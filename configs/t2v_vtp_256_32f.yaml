experiment_name: t2v_vtp_256_32f
output_dir: runs
seed: 42

video:
  width: 448
  height: 256
  fps: 16
  num_frames: 32
  frame_stride: 2

tokenizer:
  type: vtp
  name_or_path: PATH_TO_VTP_CHECKPOINT
  latent_f: 16
  latent_d: 64

text_encoder:
  type: hf
  name_or_path: openai/clip-vit-base-patch32
  max_length: 77
  freeze: true

model:
  dim: 512
  depth: 12
  num_heads: 8
  window_size: 8
  mlp_ratio: 4.0
  dropout: 0.0

diffusion:
  num_timesteps: 1000
  schedule: cosine
  prediction_type: eps

train:
  precision: bf16
  batch_size: 1
  grad_accum_steps: 16
  lr: 0.0001
  weight_decay: 0.01
  max_steps: 20000
  log_every_steps: 50
  save_every_steps: 1000
  cfg_dropout_prob: 0.1

lora:
  enabled: false
  rank: 16
  alpha: 16
  dropout: 0.0
  train_lora_only: true
  target_modules: [q, k, v, proj]


