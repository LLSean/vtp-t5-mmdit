experiment_name: t2v_vtp_smoke_256
output_dir: runs
seed: 42

# * Video spec (verification stage).
video:
  width: 448
  height: 256
  fps: 16

  # * Training sub-clip sampling.
  # * Example: num_frames=16, frame_stride=5 covers ~5 seconds at 16fps (16*5=80 frames).
  num_frames: 16
  frame_stride: 5

# * VTP tokenizer config.
tokenizer:
  type: vtp
  name_or_path: PATH_TO_VTP_CHECKPOINT
  latent_f: 16
  latent_d: 64

# * Text encoder config.
# * For the first smoke run, keep it minimal and deterministic (no downloads).
text_encoder:
  type: hash
  dim: 512
  max_length: 128

model:
  dim: 512
  depth: 8
  num_heads: 8
  window_size: 8
  mlp_ratio: 4.0
  dropout: 0.0

diffusion:
  num_timesteps: 1000
  schedule: cosine
  prediction_type: eps

train:
  precision: bf16
  batch_size: 1
  grad_accum_steps: 8
  lr: 0.0001
  weight_decay: 0.01
  max_steps: 2000
  log_every_steps: 50
  save_every_steps: 500

  # * Classifier-free guidance training.
  cfg_dropout_prob: 0.1

lora:
  enabled: false
  rank: 16
  alpha: 16
  dropout: 0.0
  train_lora_only: true
  target_modules:
    - q
    - k
    - v
    - proj


